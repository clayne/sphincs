#include "sha256.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

void sha256_testvectors() {
  unsigned char *in = (unsigned char *)calloc(64*8, sizeof(unsigned char));
  unsigned char *out256 = (unsigned char *)calloc(32*8, sizeof(unsigned char));
  unsigned char *out512 = (unsigned char *)calloc(32*8, sizeof(unsigned char));

  // Testvector for SHA-256 http://csrc.nist.gov/groups/ST/toolkit/documents/Examples/SHA_All.pdf (Page 14)
  unsigned char testvector256[32] = {0xbf,0x16,0x78,0xba,0xea,0xcf,0x01,0x8f,
                                     0xde,0x40,0x41,0x41,0x23,0x22,0xae,0x5d,
                                     0xa3,0x61,0x03,0xb0,0x9c,0x7a,0x17,0x96,
                                     0x61,0xff,0x10,0xb4,0xad,0x15,0x00,0xf2};

  // Input "abc" with padding.
  memset(in, 0, 64*8);

  int i;
  for(i = 0; i < 8; i++) {
    in[0 + 64*i] = 0x80;
    in[1 + 64*i] = 0x63;
    in[2 + 64*i] = 0x62;
    in[3 + 64*i] = 0x61;
    in[60 + 64*i] = 0x18;
  }

  sha256(out256, in);

  // Verify output
  for(i = 0; i < 8*32; i++) {
    if (out256[i % 32] != testvector256[i % 32]) {
      printf("Error: testvector incorrect for Sha256 at position %i.\n", i);
      return;
    }
  }
}

void sha256_f(unsigned char *out, const unsigned char *in) {
    unsigned char x[64];
    int i;

    for(i=0;i<32;i++)
    {
      x[i]    = in[i];
      x[i+32] = 0;
    }
    sha256(out, x);
}

void sha256_f_8x(unsigned char *out, const unsigned char *in) {
    unsigned char x[64 * 8];
    int i, j;
    for(i=0;i<32;i++)
    {
        for (j=0;j<8;j++) {
            x[64*j + i] = in[32*j + i];
            x[64*j + i+32] = 0;
        }
    }

    sha256_4x(out, x);
    sha256_4x(out + 128, x + 256);
}

void sha256_h(unsigned char *out, const unsigned char *in) {
    sha256(out, in);
}

void sha256_h_8x(unsigned char *out, const unsigned char *in) {
    sha256_4x(out, in);
    sha256_4x(out + 128, in + 256);
}

void sha256(unsigned char *out, const unsigned char *in) {
    uint32x4_t s[2];
    uint32x4_t s_save[2];
    uint32x4_t m[4];
    uint32x4_t tmp[3];

    uint32_t IV[8] = {0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
                      0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19};

    // Load initial value
    s[0] = vld1q_u32(&IV[0]);
    s[1] = vld1q_u32(&IV[4]);

    // Save state for feed-forward
    s_save[0] = s[0];
    s_save[1] = s[1];

    // Load message
    m[0] = vld1q_u32((const uint32_t *)(in +  0));
    m[1] = vld1q_u32((const uint32_t *)(in + 16));
    m[2] = vld1q_u32((const uint32_t *)(in + 32));
    m[3] = vld1q_u32((const uint32_t *)(in + 48));

    tmp[0] = vaddq_u32(m[0], vld1q_u32(&RC[0x00]));

    // Apply 4 rounds at a time using ARM instructions
    m[0] = vsha256su0q_u32(m[0], m[1]);
    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[1], vld1q_u32(&RC[0x04]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);
    m[0] = vsha256su1q_u32(m[0], m[2], m[3]);

    m[1] = vsha256su0q_u32(m[1], m[2]);
    tmp[2] = s[0];
    tmp[0] = vaddq_u32(m[2], vld1q_u32(&RC[0x08]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);
    m[1] = vsha256su1q_u32(m[1], m[3], m[0]);

    m[2] = vsha256su0q_u32(m[2], m[3]);
    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[3], vld1q_u32(&RC[0x0c]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);
    m[2] = vsha256su1q_u32(m[2], m[0], m[1]);

    m[3] = vsha256su0q_u32(m[3], m[0]);
    tmp[2] = s[0];
    tmp[0] = vaddq_u32(m[0], vld1q_u32(&RC[0x10]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);
    m[3] = vsha256su1q_u32(m[3], m[1], m[2]);

    m[0] = vsha256su0q_u32(m[0], m[1]);
    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[1], vld1q_u32(&RC[0x14]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);
    m[0] = vsha256su1q_u32(m[0], m[2], m[3]);

    m[1] = vsha256su0q_u32(m[1], m[2]);
    tmp[2] = s[0];
    tmp[0] = vaddq_u32(m[2], vld1q_u32(&RC[0x18]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);
    m[1] = vsha256su1q_u32(m[1], m[3], m[0]);

    m[2] = vsha256su0q_u32(m[2], m[3]);
    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[3], vld1q_u32(&RC[0x1c]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);
    m[2] = vsha256su1q_u32(m[2], m[0], m[1]);

    m[3] = vsha256su0q_u32(m[3], m[0]);
    tmp[2] = s[0];
    tmp[0] = vaddq_u32(m[0], vld1q_u32(&RC[0x20]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);
    m[3] = vsha256su1q_u32(m[3], m[1], m[2]);

    m[0] = vsha256su0q_u32(m[0], m[1]);
    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[1], vld1q_u32(&RC[0x24]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);
    m[0] = vsha256su1q_u32(m[0], m[2], m[3]);

    m[1] = vsha256su0q_u32(m[1], m[2]);
    tmp[2] = s[0];
    tmp[0] = vaddq_u32(m[2], vld1q_u32(&RC[0x28]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);
    m[1] = vsha256su1q_u32(m[1], m[3], m[0]);

    m[2] = vsha256su0q_u32(m[2], m[3]);
    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[3], vld1q_u32(&RC[0x2c]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);
    m[2] = vsha256su1q_u32(m[2], m[0], m[1]);

    m[3] = vsha256su0q_u32(m[3], m[0]);
    tmp[2] = s[0];
    tmp[0] = vaddq_u32(m[0], vld1q_u32(&RC[0x30]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);
    m[3] = vsha256su1q_u32(m[3], m[1], m[2]);

    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[1], vld1q_u32(&RC[0x34]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);

    tmp[2] = s[0];
    tmp[0] = vaddq_u32(m[2], vld1q_u32(&RC[0x38]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);

    tmp[2] = s[0];
    tmp[1] = vaddq_u32(m[3], vld1q_u32(&RC[0x3c]));
    s[0] = vsha256hq_u32(s[0], s[1], tmp[0]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[0]);

    tmp[2] = s[0];
    s[0] = vsha256hq_u32(s[0], s[1], tmp[1]);
    s[1] = vsha256h2q_u32(s[1], tmp[2], tmp[1]);

    // Feed-forward
    s[0] = vaddq_u32(s[0], s_save[0]);
    s[1] = vaddq_u32(s[1], s_save[1]);

    // Store to output
    vst1q_u32((uint32_t*)out, s[0]);
    vst1q_u32((uint32_t*)(out + 16), s[1]);
}

void sha256_4x(unsigned char *out, const unsigned char *in) {
    uint32x4_t s[4][2];
    uint32x4_t s_save[4][2];
    uint32x4_t m[4][4];
    uint32x4_t tmp[4][3];
    uint32_t IV[8] = {0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
                     0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19};
    s[0][0] = vld1q_u32(&IV[0]);
    s[0][1] = vld1q_u32(&IV[4]);
    s[1][0] = vld1q_u32(&IV[0]);
    s[1][1] = vld1q_u32(&IV[4]);
    s[2][0] = vld1q_u32(&IV[0]);
    s[2][1] = vld1q_u32(&IV[4]);
    s[3][0] = vld1q_u32(&IV[0]);
    s[3][1] = vld1q_u32(&IV[4]);
    s_save[0][0] = s[0][0];
    s_save[0][1] = s[0][1];
    s_save[1][0] = s[1][0];
    s_save[1][1] = s[1][1];
    s_save[2][0] = s[2][0];
    s_save[2][1] = s[2][1];
    s_save[3][0] = s[3][0];
    s_save[3][1] = s[3][1];
    m[0][0] = vld1q_u32((const uint32_t *)(in +  0 + 0));
    m[0][1] = vld1q_u32((const uint32_t *)(in + 16 + 0));
    m[0][2] = vld1q_u32((const uint32_t *)(in + 32 + 0));
    m[0][3] = vld1q_u32((const uint32_t *)(in + 48 + 0));
    m[1][0] = vld1q_u32((const uint32_t *)(in +  0 + 64));
    m[1][1] = vld1q_u32((const uint32_t *)(in + 16 + 64));
    m[1][2] = vld1q_u32((const uint32_t *)(in + 32 + 64));
    m[1][3] = vld1q_u32((const uint32_t *)(in + 48 + 64));
    m[2][0] = vld1q_u32((const uint32_t *)(in +  0 + 128));
    m[2][1] = vld1q_u32((const uint32_t *)(in + 16 + 128));
    m[2][2] = vld1q_u32((const uint32_t *)(in + 32 + 128));
    m[2][3] = vld1q_u32((const uint32_t *)(in + 48 + 128));
    m[3][0] = vld1q_u32((const uint32_t *)(in +  0 + 192));
    m[3][1] = vld1q_u32((const uint32_t *)(in + 16 + 192));
    m[3][2] = vld1q_u32((const uint32_t *)(in + 32 + 192));
    m[3][3] = vld1q_u32((const uint32_t *)(in + 48 + 192));
    m[0][0] = vsha256su0q_u32(m[0][0], m[0][1]);
    m[1][0] = vsha256su0q_u32(m[1][0], m[1][1]);
    m[2][0] = vsha256su0q_u32(m[2][0], m[2][1]);
    m[3][0] = vsha256su0q_u32(m[3][0], m[3][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x04]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x04]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x04]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x04]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    m[0][0] = vsha256su1q_u32(m[0][0], m[0][2], m[0][3]);
    m[1][0] = vsha256su1q_u32(m[1][0], m[1][2], m[1][3]);
    m[2][0] = vsha256su1q_u32(m[2][0], m[2][2], m[2][3]);
    m[3][0] = vsha256su1q_u32(m[3][0], m[3][2], m[3][3]);
    m[0][1] = vsha256su0q_u32(m[0][1], m[0][2]);
    m[1][1] = vsha256su0q_u32(m[1][1], m[1][2]);
    m[2][1] = vsha256su0q_u32(m[2][1], m[2][2]);
    m[3][1] = vsha256su0q_u32(m[3][1], m[3][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x08]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x08]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x08]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x08]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    m[0][1] = vsha256su1q_u32(m[0][1], m[0][3], m[0][0]);
    m[1][1] = vsha256su1q_u32(m[1][1], m[1][3], m[1][0]);
    m[2][1] = vsha256su1q_u32(m[2][1], m[2][3], m[2][0]);
    m[3][1] = vsha256su1q_u32(m[3][1], m[3][3], m[3][0]);
    m[0][2] = vsha256su0q_u32(m[0][2], m[0][3]);
    m[1][2] = vsha256su0q_u32(m[1][2], m[1][3]);
    m[2][2] = vsha256su0q_u32(m[2][2], m[2][3]);
    m[3][2] = vsha256su0q_u32(m[3][2], m[3][3]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x0c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x0c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x0c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x0c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    m[0][2] = vsha256su1q_u32(m[0][2], m[0][0], m[0][1]);
    m[1][2] = vsha256su1q_u32(m[1][2], m[1][0], m[1][1]);
    m[2][2] = vsha256su1q_u32(m[2][2], m[2][0], m[2][1]);
    m[3][2] = vsha256su1q_u32(m[3][2], m[3][0], m[3][1]);
    m[0][3] = vsha256su0q_u32(m[0][3], m[0][0]);
    m[1][3] = vsha256su0q_u32(m[1][3], m[1][0]);
    m[2][3] = vsha256su0q_u32(m[2][3], m[2][0]);
    m[3][3] = vsha256su0q_u32(m[3][3], m[3][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][0] = vaddq_u32(m[0][0], vld1q_u32(&RC[0x10]));
    tmp[1][0] = vaddq_u32(m[1][0], vld1q_u32(&RC[0x10]));
    tmp[2][0] = vaddq_u32(m[2][0], vld1q_u32(&RC[0x10]));
    tmp[3][0] = vaddq_u32(m[3][0], vld1q_u32(&RC[0x10]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    m[0][3] = vsha256su1q_u32(m[0][3], m[0][1], m[0][2]);
    m[1][3] = vsha256su1q_u32(m[1][3], m[1][1], m[1][2]);
    m[2][3] = vsha256su1q_u32(m[2][3], m[2][1], m[2][2]);
    m[3][3] = vsha256su1q_u32(m[3][3], m[3][1], m[3][2]);
    m[0][0] = vsha256su0q_u32(m[0][0], m[0][1]);
    m[1][0] = vsha256su0q_u32(m[1][0], m[1][1]);
    m[2][0] = vsha256su0q_u32(m[2][0], m[2][1]);
    m[3][0] = vsha256su0q_u32(m[3][0], m[3][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x14]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x14]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x14]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x14]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    m[0][0] = vsha256su1q_u32(m[0][0], m[0][2], m[0][3]);
    m[1][0] = vsha256su1q_u32(m[1][0], m[1][2], m[1][3]);
    m[2][0] = vsha256su1q_u32(m[2][0], m[2][2], m[2][3]);
    m[3][0] = vsha256su1q_u32(m[3][0], m[3][2], m[3][3]);
    m[0][1] = vsha256su0q_u32(m[0][1], m[0][2]);
    m[1][1] = vsha256su0q_u32(m[1][1], m[1][2]);
    m[2][1] = vsha256su0q_u32(m[2][1], m[2][2]);
    m[3][1] = vsha256su0q_u32(m[3][1], m[3][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x18]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x18]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x18]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x18]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    m[0][1] = vsha256su1q_u32(m[0][1], m[0][3], m[0][0]);
    m[1][1] = vsha256su1q_u32(m[1][1], m[1][3], m[1][0]);
    m[2][1] = vsha256su1q_u32(m[2][1], m[2][3], m[2][0]);
    m[3][1] = vsha256su1q_u32(m[3][1], m[3][3], m[3][0]);
    m[0][2] = vsha256su0q_u32(m[0][2], m[0][3]);
    m[1][2] = vsha256su0q_u32(m[1][2], m[1][3]);
    m[2][2] = vsha256su0q_u32(m[2][2], m[2][3]);
    m[3][2] = vsha256su0q_u32(m[3][2], m[3][3]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x1c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x1c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x1c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x1c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    m[0][2] = vsha256su1q_u32(m[0][2], m[0][0], m[0][1]);
    m[1][2] = vsha256su1q_u32(m[1][2], m[1][0], m[1][1]);
    m[2][2] = vsha256su1q_u32(m[2][2], m[2][0], m[2][1]);
    m[3][2] = vsha256su1q_u32(m[3][2], m[3][0], m[3][1]);
    m[0][3] = vsha256su0q_u32(m[0][3], m[0][0]);
    m[1][3] = vsha256su0q_u32(m[1][3], m[1][0]);
    m[2][3] = vsha256su0q_u32(m[2][3], m[2][0]);
    m[3][3] = vsha256su0q_u32(m[3][3], m[3][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][0] = vaddq_u32(m[0][0], vld1q_u32(&RC[0x20]));
    tmp[1][0] = vaddq_u32(m[1][0], vld1q_u32(&RC[0x20]));
    tmp[2][0] = vaddq_u32(m[2][0], vld1q_u32(&RC[0x20]));
    tmp[3][0] = vaddq_u32(m[3][0], vld1q_u32(&RC[0x20]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    m[0][3] = vsha256su1q_u32(m[0][3], m[0][1], m[0][2]);
    m[1][3] = vsha256su1q_u32(m[1][3], m[1][1], m[1][2]);
    m[2][3] = vsha256su1q_u32(m[2][3], m[2][1], m[2][2]);
    m[3][3] = vsha256su1q_u32(m[3][3], m[3][1], m[3][2]);
    m[0][0] = vsha256su0q_u32(m[0][0], m[0][1]);
    m[1][0] = vsha256su0q_u32(m[1][0], m[1][1]);
    m[2][0] = vsha256su0q_u32(m[2][0], m[2][1]);
    m[3][0] = vsha256su0q_u32(m[3][0], m[3][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x24]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x24]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x24]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x24]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    m[0][0] = vsha256su1q_u32(m[0][0], m[0][2], m[0][3]);
    m[1][0] = vsha256su1q_u32(m[1][0], m[1][2], m[1][3]);
    m[2][0] = vsha256su1q_u32(m[2][0], m[2][2], m[2][3]);
    m[3][0] = vsha256su1q_u32(m[3][0], m[3][2], m[3][3]);
    m[0][1] = vsha256su0q_u32(m[0][1], m[0][2]);
    m[1][1] = vsha256su0q_u32(m[1][1], m[1][2]);
    m[2][1] = vsha256su0q_u32(m[2][1], m[2][2]);
    m[3][1] = vsha256su0q_u32(m[3][1], m[3][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x28]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x28]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x28]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x28]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    m[0][1] = vsha256su1q_u32(m[0][1], m[0][3], m[0][0]);
    m[1][1] = vsha256su1q_u32(m[1][1], m[1][3], m[1][0]);
    m[2][1] = vsha256su1q_u32(m[2][1], m[2][3], m[2][0]);
    m[3][1] = vsha256su1q_u32(m[3][1], m[3][3], m[3][0]);
    m[0][2] = vsha256su0q_u32(m[0][2], m[0][3]);
    m[1][2] = vsha256su0q_u32(m[1][2], m[1][3]);
    m[2][2] = vsha256su0q_u32(m[2][2], m[2][3]);
    m[3][2] = vsha256su0q_u32(m[3][2], m[3][3]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x2c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x2c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x2c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x2c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    m[0][2] = vsha256su1q_u32(m[0][2], m[0][0], m[0][1]);
    m[1][2] = vsha256su1q_u32(m[1][2], m[1][0], m[1][1]);
    m[2][2] = vsha256su1q_u32(m[2][2], m[2][0], m[2][1]);
    m[3][2] = vsha256su1q_u32(m[3][2], m[3][0], m[3][1]);
    m[0][3] = vsha256su0q_u32(m[0][3], m[0][0]);
    m[1][3] = vsha256su0q_u32(m[1][3], m[1][0]);
    m[2][3] = vsha256su0q_u32(m[2][3], m[2][0]);
    m[3][3] = vsha256su0q_u32(m[3][3], m[3][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][0] = vaddq_u32(m[0][0], vld1q_u32(&RC[0x30]));
    tmp[1][0] = vaddq_u32(m[1][0], vld1q_u32(&RC[0x30]));
    tmp[2][0] = vaddq_u32(m[2][0], vld1q_u32(&RC[0x30]));
    tmp[3][0] = vaddq_u32(m[3][0], vld1q_u32(&RC[0x30]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    m[0][3] = vsha256su1q_u32(m[0][3], m[0][1], m[0][2]);
    m[1][3] = vsha256su1q_u32(m[1][3], m[1][1], m[1][2]);
    m[2][3] = vsha256su1q_u32(m[2][3], m[2][1], m[2][2]);
    m[3][3] = vsha256su1q_u32(m[3][3], m[3][1], m[3][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x34]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x34]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x34]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x34]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x38]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x38]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x38]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x38]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x3c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x3c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x3c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x3c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[0][0]  = vaddq_u32(s[0][0], s_save[0][0]);
    s[0][1]  = vaddq_u32(s[0][1], s_save[0][1]);
    s[1][0]  = vaddq_u32(s[1][0], s_save[1][0]);
    s[1][1]  = vaddq_u32(s[1][1], s_save[1][1]);
    s[2][0]  = vaddq_u32(s[2][0], s_save[2][0]);
    s[2][1]  = vaddq_u32(s[2][1], s_save[2][1]);
    s[3][0]  = vaddq_u32(s[3][0], s_save[3][0]);
    s[3][1]  = vaddq_u32(s[3][1], s_save[3][1]);
    vst1q_u32((uint32_t*)(out + 0), s[0][0]);
    vst1q_u32((uint32_t*)(out + 16), s[0][1]);
    vst1q_u32((uint32_t*)(out + 32), s[1][0]);
    vst1q_u32((uint32_t*)(out + 48), s[1][1]);
    vst1q_u32((uint32_t*)(out + 64), s[2][0]);
    vst1q_u32((uint32_t*)(out + 80), s[2][1]);
    vst1q_u32((uint32_t*)(out + 96), s[3][0]);
    vst1q_u32((uint32_t*)(out + 112), s[3][1]);
}

void sha256_8x(unsigned char *out, const unsigned char *in) {
   uint32x4_t s[8][2];
   uint32x4_t s_save[8][2];
   uint32x4_t m[8][4];
   uint32x4_t tmp[8][3];
    uint32_t IV[8] = {0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
                     0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19};
    s[0][0] = vld1q_u32(&IV[0]);
    s[0][1] = vld1q_u32(&IV[4]);
    s[1][0] = vld1q_u32(&IV[0]);
    s[1][1] = vld1q_u32(&IV[4]);
    s[2][0] = vld1q_u32(&IV[0]);
    s[2][1] = vld1q_u32(&IV[4]);
    s[3][0] = vld1q_u32(&IV[0]);
    s[3][1] = vld1q_u32(&IV[4]);
    s[4][0] = vld1q_u32(&IV[0]);
    s[4][1] = vld1q_u32(&IV[4]);
    s[5][0] = vld1q_u32(&IV[0]);
    s[5][1] = vld1q_u32(&IV[4]);
    s[6][0] = vld1q_u32(&IV[0]);
    s[6][1] = vld1q_u32(&IV[4]);
    s[7][0] = vld1q_u32(&IV[0]);
    s[7][1] = vld1q_u32(&IV[4]);
    s_save[0][0] = s[0][0];
    s_save[0][1] = s[0][1];
    s_save[1][0] = s[1][0];
    s_save[1][1] = s[1][1];
    s_save[2][0] = s[2][0];
    s_save[2][1] = s[2][1];
    s_save[3][0] = s[3][0];
    s_save[3][1] = s[3][1];
    s_save[4][0] = s[4][0];
    s_save[4][1] = s[4][1];
    s_save[5][0] = s[5][0];
    s_save[5][1] = s[5][1];
    s_save[6][0] = s[6][0];
    s_save[6][1] = s[6][1];
    s_save[7][0] = s[7][0];
    s_save[7][1] = s[7][1];
    m[0][0] = vld1q_u32((const uint32_t *)(in +  0 + 0));
    m[0][1] = vld1q_u32((const uint32_t *)(in + 16 + 0));
    m[0][2] = vld1q_u32((const uint32_t *)(in + 32 + 0));
    m[0][3] = vld1q_u32((const uint32_t *)(in + 48 + 0));
    m[1][0] = vld1q_u32((const uint32_t *)(in +  0 + 64));
    m[1][1] = vld1q_u32((const uint32_t *)(in + 16 + 64));
    m[1][2] = vld1q_u32((const uint32_t *)(in + 32 + 64));
    m[1][3] = vld1q_u32((const uint32_t *)(in + 48 + 64));
    m[2][0] = vld1q_u32((const uint32_t *)(in +  0 + 128));
    m[2][1] = vld1q_u32((const uint32_t *)(in + 16 + 128));
    m[2][2] = vld1q_u32((const uint32_t *)(in + 32 + 128));
    m[2][3] = vld1q_u32((const uint32_t *)(in + 48 + 128));
    m[3][0] = vld1q_u32((const uint32_t *)(in +  0 + 192));
    m[3][1] = vld1q_u32((const uint32_t *)(in + 16 + 192));
    m[3][2] = vld1q_u32((const uint32_t *)(in + 32 + 192));
    m[3][3] = vld1q_u32((const uint32_t *)(in + 48 + 192));
    m[4][0] = vld1q_u32((const uint32_t *)(in +  0 + 256));
    m[4][1] = vld1q_u32((const uint32_t *)(in + 16 + 256));
    m[4][2] = vld1q_u32((const uint32_t *)(in + 32 + 256));
    m[4][3] = vld1q_u32((const uint32_t *)(in + 48 + 256));
    m[5][0] = vld1q_u32((const uint32_t *)(in +  0 + 320));
    m[5][1] = vld1q_u32((const uint32_t *)(in + 16 + 320));
    m[5][2] = vld1q_u32((const uint32_t *)(in + 32 + 320));
    m[5][3] = vld1q_u32((const uint32_t *)(in + 48 + 320));
    m[6][0] = vld1q_u32((const uint32_t *)(in +  0 + 384));
    m[6][1] = vld1q_u32((const uint32_t *)(in + 16 + 384));
    m[6][2] = vld1q_u32((const uint32_t *)(in + 32 + 384));
    m[6][3] = vld1q_u32((const uint32_t *)(in + 48 + 384));
    m[7][0] = vld1q_u32((const uint32_t *)(in +  0 + 448));
    m[7][1] = vld1q_u32((const uint32_t *)(in + 16 + 448));
    m[7][2] = vld1q_u32((const uint32_t *)(in + 32 + 448));
    m[7][3] = vld1q_u32((const uint32_t *)(in + 48 + 448));
    m[0][0] = vsha256su0q_u32(m[0][0], m[0][1]);
    m[1][0] = vsha256su0q_u32(m[1][0], m[1][1]);
    m[2][0] = vsha256su0q_u32(m[2][0], m[2][1]);
    m[3][0] = vsha256su0q_u32(m[3][0], m[3][1]);
    m[4][0] = vsha256su0q_u32(m[4][0], m[4][1]);
    m[5][0] = vsha256su0q_u32(m[5][0], m[5][1]);
    m[6][0] = vsha256su0q_u32(m[6][0], m[6][1]);
    m[7][0] = vsha256su0q_u32(m[7][0], m[7][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x04]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x04]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x04]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x04]));
    tmp[4][1] = vaddq_u32(m[4][1], vld1q_u32(&RC[0x04]));
    tmp[5][1] = vaddq_u32(m[5][1], vld1q_u32(&RC[0x04]));
    tmp[6][1] = vaddq_u32(m[6][1], vld1q_u32(&RC[0x04]));
    tmp[7][1] = vaddq_u32(m[7][1], vld1q_u32(&RC[0x04]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    m[0][0] = vsha256su1q_u32(m[0][0], m[0][2], m[0][3]);
    m[1][0] = vsha256su1q_u32(m[1][0], m[1][2], m[1][3]);
    m[2][0] = vsha256su1q_u32(m[2][0], m[2][2], m[2][3]);
    m[3][0] = vsha256su1q_u32(m[3][0], m[3][2], m[3][3]);
    m[4][0] = vsha256su1q_u32(m[4][0], m[4][2], m[4][3]);
    m[5][0] = vsha256su1q_u32(m[5][0], m[5][2], m[5][3]);
    m[6][0] = vsha256su1q_u32(m[6][0], m[6][2], m[6][3]);
    m[7][0] = vsha256su1q_u32(m[7][0], m[7][2], m[7][3]);
    m[0][1] = vsha256su0q_u32(m[0][1], m[0][2]);
    m[1][1] = vsha256su0q_u32(m[1][1], m[1][2]);
    m[2][1] = vsha256su0q_u32(m[2][1], m[2][2]);
    m[3][1] = vsha256su0q_u32(m[3][1], m[3][2]);
    m[4][1] = vsha256su0q_u32(m[4][1], m[4][2]);
    m[5][1] = vsha256su0q_u32(m[5][1], m[5][2]);
    m[6][1] = vsha256su0q_u32(m[6][1], m[6][2]);
    m[7][1] = vsha256su0q_u32(m[7][1], m[7][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x08]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x08]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x08]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x08]));
    tmp[4][0] = vaddq_u32(m[4][2], vld1q_u32(&RC[0x08]));
    tmp[5][0] = vaddq_u32(m[5][2], vld1q_u32(&RC[0x08]));
    tmp[6][0] = vaddq_u32(m[6][2], vld1q_u32(&RC[0x08]));
    tmp[7][0] = vaddq_u32(m[7][2], vld1q_u32(&RC[0x08]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    m[0][1] = vsha256su1q_u32(m[0][1], m[0][3], m[0][0]);
    m[1][1] = vsha256su1q_u32(m[1][1], m[1][3], m[1][0]);
    m[2][1] = vsha256su1q_u32(m[2][1], m[2][3], m[2][0]);
    m[3][1] = vsha256su1q_u32(m[3][1], m[3][3], m[3][0]);
    m[4][1] = vsha256su1q_u32(m[4][1], m[4][3], m[4][0]);
    m[5][1] = vsha256su1q_u32(m[5][1], m[5][3], m[5][0]);
    m[6][1] = vsha256su1q_u32(m[6][1], m[6][3], m[6][0]);
    m[7][1] = vsha256su1q_u32(m[7][1], m[7][3], m[7][0]);
    m[0][2] = vsha256su0q_u32(m[0][2], m[0][3]);
    m[1][2] = vsha256su0q_u32(m[1][2], m[1][3]);
    m[2][2] = vsha256su0q_u32(m[2][2], m[2][3]);
    m[3][2] = vsha256su0q_u32(m[3][2], m[3][3]);
    m[4][2] = vsha256su0q_u32(m[4][2], m[4][3]);
    m[5][2] = vsha256su0q_u32(m[5][2], m[5][3]);
    m[6][2] = vsha256su0q_u32(m[6][2], m[6][3]);
    m[7][2] = vsha256su0q_u32(m[7][2], m[7][3]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x0c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x0c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x0c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x0c]));
    tmp[4][1] = vaddq_u32(m[4][3], vld1q_u32(&RC[0x0c]));
    tmp[5][1] = vaddq_u32(m[5][3], vld1q_u32(&RC[0x0c]));
    tmp[6][1] = vaddq_u32(m[6][3], vld1q_u32(&RC[0x0c]));
    tmp[7][1] = vaddq_u32(m[7][3], vld1q_u32(&RC[0x0c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    m[0][2] = vsha256su1q_u32(m[0][2], m[0][0], m[0][1]);
    m[1][2] = vsha256su1q_u32(m[1][2], m[1][0], m[1][1]);
    m[2][2] = vsha256su1q_u32(m[2][2], m[2][0], m[2][1]);
    m[3][2] = vsha256su1q_u32(m[3][2], m[3][0], m[3][1]);
    m[4][2] = vsha256su1q_u32(m[4][2], m[4][0], m[4][1]);
    m[5][2] = vsha256su1q_u32(m[5][2], m[5][0], m[5][1]);
    m[6][2] = vsha256su1q_u32(m[6][2], m[6][0], m[6][1]);
    m[7][2] = vsha256su1q_u32(m[7][2], m[7][0], m[7][1]);
    m[0][3] = vsha256su0q_u32(m[0][3], m[0][0]);
    m[1][3] = vsha256su0q_u32(m[1][3], m[1][0]);
    m[2][3] = vsha256su0q_u32(m[2][3], m[2][0]);
    m[3][3] = vsha256su0q_u32(m[3][3], m[3][0]);
    m[4][3] = vsha256su0q_u32(m[4][3], m[4][0]);
    m[5][3] = vsha256su0q_u32(m[5][3], m[5][0]);
    m[6][3] = vsha256su0q_u32(m[6][3], m[6][0]);
    m[7][3] = vsha256su0q_u32(m[7][3], m[7][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][0] = vaddq_u32(m[0][0], vld1q_u32(&RC[0x10]));
    tmp[1][0] = vaddq_u32(m[1][0], vld1q_u32(&RC[0x10]));
    tmp[2][0] = vaddq_u32(m[2][0], vld1q_u32(&RC[0x10]));
    tmp[3][0] = vaddq_u32(m[3][0], vld1q_u32(&RC[0x10]));
    tmp[4][0] = vaddq_u32(m[4][0], vld1q_u32(&RC[0x10]));
    tmp[5][0] = vaddq_u32(m[5][0], vld1q_u32(&RC[0x10]));
    tmp[6][0] = vaddq_u32(m[6][0], vld1q_u32(&RC[0x10]));
    tmp[7][0] = vaddq_u32(m[7][0], vld1q_u32(&RC[0x10]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    m[0][3] = vsha256su1q_u32(m[0][3], m[0][1], m[0][2]);
    m[1][3] = vsha256su1q_u32(m[1][3], m[1][1], m[1][2]);
    m[2][3] = vsha256su1q_u32(m[2][3], m[2][1], m[2][2]);
    m[3][3] = vsha256su1q_u32(m[3][3], m[3][1], m[3][2]);
    m[4][3] = vsha256su1q_u32(m[4][3], m[4][1], m[4][2]);
    m[5][3] = vsha256su1q_u32(m[5][3], m[5][1], m[5][2]);
    m[6][3] = vsha256su1q_u32(m[6][3], m[6][1], m[6][2]);
    m[7][3] = vsha256su1q_u32(m[7][3], m[7][1], m[7][2]);
    m[0][0] = vsha256su0q_u32(m[0][0], m[0][1]);
    m[1][0] = vsha256su0q_u32(m[1][0], m[1][1]);
    m[2][0] = vsha256su0q_u32(m[2][0], m[2][1]);
    m[3][0] = vsha256su0q_u32(m[3][0], m[3][1]);
    m[4][0] = vsha256su0q_u32(m[4][0], m[4][1]);
    m[5][0] = vsha256su0q_u32(m[5][0], m[5][1]);
    m[6][0] = vsha256su0q_u32(m[6][0], m[6][1]);
    m[7][0] = vsha256su0q_u32(m[7][0], m[7][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x14]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x14]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x14]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x14]));
    tmp[4][1] = vaddq_u32(m[4][1], vld1q_u32(&RC[0x14]));
    tmp[5][1] = vaddq_u32(m[5][1], vld1q_u32(&RC[0x14]));
    tmp[6][1] = vaddq_u32(m[6][1], vld1q_u32(&RC[0x14]));
    tmp[7][1] = vaddq_u32(m[7][1], vld1q_u32(&RC[0x14]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    m[0][0] = vsha256su1q_u32(m[0][0], m[0][2], m[0][3]);
    m[1][0] = vsha256su1q_u32(m[1][0], m[1][2], m[1][3]);
    m[2][0] = vsha256su1q_u32(m[2][0], m[2][2], m[2][3]);
    m[3][0] = vsha256su1q_u32(m[3][0], m[3][2], m[3][3]);
    m[4][0] = vsha256su1q_u32(m[4][0], m[4][2], m[4][3]);
    m[5][0] = vsha256su1q_u32(m[5][0], m[5][2], m[5][3]);
    m[6][0] = vsha256su1q_u32(m[6][0], m[6][2], m[6][3]);
    m[7][0] = vsha256su1q_u32(m[7][0], m[7][2], m[7][3]);
    m[0][1] = vsha256su0q_u32(m[0][1], m[0][2]);
    m[1][1] = vsha256su0q_u32(m[1][1], m[1][2]);
    m[2][1] = vsha256su0q_u32(m[2][1], m[2][2]);
    m[3][1] = vsha256su0q_u32(m[3][1], m[3][2]);
    m[4][1] = vsha256su0q_u32(m[4][1], m[4][2]);
    m[5][1] = vsha256su0q_u32(m[5][1], m[5][2]);
    m[6][1] = vsha256su0q_u32(m[6][1], m[6][2]);
    m[7][1] = vsha256su0q_u32(m[7][1], m[7][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x18]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x18]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x18]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x18]));
    tmp[4][0] = vaddq_u32(m[4][2], vld1q_u32(&RC[0x18]));
    tmp[5][0] = vaddq_u32(m[5][2], vld1q_u32(&RC[0x18]));
    tmp[6][0] = vaddq_u32(m[6][2], vld1q_u32(&RC[0x18]));
    tmp[7][0] = vaddq_u32(m[7][2], vld1q_u32(&RC[0x18]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    m[0][1] = vsha256su1q_u32(m[0][1], m[0][3], m[0][0]);
    m[1][1] = vsha256su1q_u32(m[1][1], m[1][3], m[1][0]);
    m[2][1] = vsha256su1q_u32(m[2][1], m[2][3], m[2][0]);
    m[3][1] = vsha256su1q_u32(m[3][1], m[3][3], m[3][0]);
    m[4][1] = vsha256su1q_u32(m[4][1], m[4][3], m[4][0]);
    m[5][1] = vsha256su1q_u32(m[5][1], m[5][3], m[5][0]);
    m[6][1] = vsha256su1q_u32(m[6][1], m[6][3], m[6][0]);
    m[7][1] = vsha256su1q_u32(m[7][1], m[7][3], m[7][0]);
    m[0][2] = vsha256su0q_u32(m[0][2], m[0][3]);
    m[1][2] = vsha256su0q_u32(m[1][2], m[1][3]);
    m[2][2] = vsha256su0q_u32(m[2][2], m[2][3]);
    m[3][2] = vsha256su0q_u32(m[3][2], m[3][3]);
    m[4][2] = vsha256su0q_u32(m[4][2], m[4][3]);
    m[5][2] = vsha256su0q_u32(m[5][2], m[5][3]);
    m[6][2] = vsha256su0q_u32(m[6][2], m[6][3]);
    m[7][2] = vsha256su0q_u32(m[7][2], m[7][3]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x1c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x1c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x1c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x1c]));
    tmp[4][1] = vaddq_u32(m[4][3], vld1q_u32(&RC[0x1c]));
    tmp[5][1] = vaddq_u32(m[5][3], vld1q_u32(&RC[0x1c]));
    tmp[6][1] = vaddq_u32(m[6][3], vld1q_u32(&RC[0x1c]));
    tmp[7][1] = vaddq_u32(m[7][3], vld1q_u32(&RC[0x1c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    m[0][2] = vsha256su1q_u32(m[0][2], m[0][0], m[0][1]);
    m[1][2] = vsha256su1q_u32(m[1][2], m[1][0], m[1][1]);
    m[2][2] = vsha256su1q_u32(m[2][2], m[2][0], m[2][1]);
    m[3][2] = vsha256su1q_u32(m[3][2], m[3][0], m[3][1]);
    m[4][2] = vsha256su1q_u32(m[4][2], m[4][0], m[4][1]);
    m[5][2] = vsha256su1q_u32(m[5][2], m[5][0], m[5][1]);
    m[6][2] = vsha256su1q_u32(m[6][2], m[6][0], m[6][1]);
    m[7][2] = vsha256su1q_u32(m[7][2], m[7][0], m[7][1]);
    m[0][3] = vsha256su0q_u32(m[0][3], m[0][0]);
    m[1][3] = vsha256su0q_u32(m[1][3], m[1][0]);
    m[2][3] = vsha256su0q_u32(m[2][3], m[2][0]);
    m[3][3] = vsha256su0q_u32(m[3][3], m[3][0]);
    m[4][3] = vsha256su0q_u32(m[4][3], m[4][0]);
    m[5][3] = vsha256su0q_u32(m[5][3], m[5][0]);
    m[6][3] = vsha256su0q_u32(m[6][3], m[6][0]);
    m[7][3] = vsha256su0q_u32(m[7][3], m[7][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][0] = vaddq_u32(m[0][0], vld1q_u32(&RC[0x20]));
    tmp[1][0] = vaddq_u32(m[1][0], vld1q_u32(&RC[0x20]));
    tmp[2][0] = vaddq_u32(m[2][0], vld1q_u32(&RC[0x20]));
    tmp[3][0] = vaddq_u32(m[3][0], vld1q_u32(&RC[0x20]));
    tmp[4][0] = vaddq_u32(m[4][0], vld1q_u32(&RC[0x20]));
    tmp[5][0] = vaddq_u32(m[5][0], vld1q_u32(&RC[0x20]));
    tmp[6][0] = vaddq_u32(m[6][0], vld1q_u32(&RC[0x20]));
    tmp[7][0] = vaddq_u32(m[7][0], vld1q_u32(&RC[0x20]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    m[0][3] = vsha256su1q_u32(m[0][3], m[0][1], m[0][2]);
    m[1][3] = vsha256su1q_u32(m[1][3], m[1][1], m[1][2]);
    m[2][3] = vsha256su1q_u32(m[2][3], m[2][1], m[2][2]);
    m[3][3] = vsha256su1q_u32(m[3][3], m[3][1], m[3][2]);
    m[4][3] = vsha256su1q_u32(m[4][3], m[4][1], m[4][2]);
    m[5][3] = vsha256su1q_u32(m[5][3], m[5][1], m[5][2]);
    m[6][3] = vsha256su1q_u32(m[6][3], m[6][1], m[6][2]);
    m[7][3] = vsha256su1q_u32(m[7][3], m[7][1], m[7][2]);
    m[0][0] = vsha256su0q_u32(m[0][0], m[0][1]);
    m[1][0] = vsha256su0q_u32(m[1][0], m[1][1]);
    m[2][0] = vsha256su0q_u32(m[2][0], m[2][1]);
    m[3][0] = vsha256su0q_u32(m[3][0], m[3][1]);
    m[4][0] = vsha256su0q_u32(m[4][0], m[4][1]);
    m[5][0] = vsha256su0q_u32(m[5][0], m[5][1]);
    m[6][0] = vsha256su0q_u32(m[6][0], m[6][1]);
    m[7][0] = vsha256su0q_u32(m[7][0], m[7][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x24]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x24]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x24]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x24]));
    tmp[4][1] = vaddq_u32(m[4][1], vld1q_u32(&RC[0x24]));
    tmp[5][1] = vaddq_u32(m[5][1], vld1q_u32(&RC[0x24]));
    tmp[6][1] = vaddq_u32(m[6][1], vld1q_u32(&RC[0x24]));
    tmp[7][1] = vaddq_u32(m[7][1], vld1q_u32(&RC[0x24]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    m[0][0] = vsha256su1q_u32(m[0][0], m[0][2], m[0][3]);
    m[1][0] = vsha256su1q_u32(m[1][0], m[1][2], m[1][3]);
    m[2][0] = vsha256su1q_u32(m[2][0], m[2][2], m[2][3]);
    m[3][0] = vsha256su1q_u32(m[3][0], m[3][2], m[3][3]);
    m[4][0] = vsha256su1q_u32(m[4][0], m[4][2], m[4][3]);
    m[5][0] = vsha256su1q_u32(m[5][0], m[5][2], m[5][3]);
    m[6][0] = vsha256su1q_u32(m[6][0], m[6][2], m[6][3]);
    m[7][0] = vsha256su1q_u32(m[7][0], m[7][2], m[7][3]);
    m[0][1] = vsha256su0q_u32(m[0][1], m[0][2]);
    m[1][1] = vsha256su0q_u32(m[1][1], m[1][2]);
    m[2][1] = vsha256su0q_u32(m[2][1], m[2][2]);
    m[3][1] = vsha256su0q_u32(m[3][1], m[3][2]);
    m[4][1] = vsha256su0q_u32(m[4][1], m[4][2]);
    m[5][1] = vsha256su0q_u32(m[5][1], m[5][2]);
    m[6][1] = vsha256su0q_u32(m[6][1], m[6][2]);
    m[7][1] = vsha256su0q_u32(m[7][1], m[7][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x28]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x28]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x28]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x28]));
    tmp[4][0] = vaddq_u32(m[4][2], vld1q_u32(&RC[0x28]));
    tmp[5][0] = vaddq_u32(m[5][2], vld1q_u32(&RC[0x28]));
    tmp[6][0] = vaddq_u32(m[6][2], vld1q_u32(&RC[0x28]));
    tmp[7][0] = vaddq_u32(m[7][2], vld1q_u32(&RC[0x28]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    m[0][1] = vsha256su1q_u32(m[0][1], m[0][3], m[0][0]);
    m[1][1] = vsha256su1q_u32(m[1][1], m[1][3], m[1][0]);
    m[2][1] = vsha256su1q_u32(m[2][1], m[2][3], m[2][0]);
    m[3][1] = vsha256su1q_u32(m[3][1], m[3][3], m[3][0]);
    m[4][1] = vsha256su1q_u32(m[4][1], m[4][3], m[4][0]);
    m[5][1] = vsha256su1q_u32(m[5][1], m[5][3], m[5][0]);
    m[6][1] = vsha256su1q_u32(m[6][1], m[6][3], m[6][0]);
    m[7][1] = vsha256su1q_u32(m[7][1], m[7][3], m[7][0]);
    m[0][2] = vsha256su0q_u32(m[0][2], m[0][3]);
    m[1][2] = vsha256su0q_u32(m[1][2], m[1][3]);
    m[2][2] = vsha256su0q_u32(m[2][2], m[2][3]);
    m[3][2] = vsha256su0q_u32(m[3][2], m[3][3]);
    m[4][2] = vsha256su0q_u32(m[4][2], m[4][3]);
    m[5][2] = vsha256su0q_u32(m[5][2], m[5][3]);
    m[6][2] = vsha256su0q_u32(m[6][2], m[6][3]);
    m[7][2] = vsha256su0q_u32(m[7][2], m[7][3]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x2c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x2c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x2c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x2c]));
    tmp[4][1] = vaddq_u32(m[4][3], vld1q_u32(&RC[0x2c]));
    tmp[5][1] = vaddq_u32(m[5][3], vld1q_u32(&RC[0x2c]));
    tmp[6][1] = vaddq_u32(m[6][3], vld1q_u32(&RC[0x2c]));
    tmp[7][1] = vaddq_u32(m[7][3], vld1q_u32(&RC[0x2c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    m[0][2] = vsha256su1q_u32(m[0][2], m[0][0], m[0][1]);
    m[1][2] = vsha256su1q_u32(m[1][2], m[1][0], m[1][1]);
    m[2][2] = vsha256su1q_u32(m[2][2], m[2][0], m[2][1]);
    m[3][2] = vsha256su1q_u32(m[3][2], m[3][0], m[3][1]);
    m[4][2] = vsha256su1q_u32(m[4][2], m[4][0], m[4][1]);
    m[5][2] = vsha256su1q_u32(m[5][2], m[5][0], m[5][1]);
    m[6][2] = vsha256su1q_u32(m[6][2], m[6][0], m[6][1]);
    m[7][2] = vsha256su1q_u32(m[7][2], m[7][0], m[7][1]);
    m[0][3] = vsha256su0q_u32(m[0][3], m[0][0]);
    m[1][3] = vsha256su0q_u32(m[1][3], m[1][0]);
    m[2][3] = vsha256su0q_u32(m[2][3], m[2][0]);
    m[3][3] = vsha256su0q_u32(m[3][3], m[3][0]);
    m[4][3] = vsha256su0q_u32(m[4][3], m[4][0]);
    m[5][3] = vsha256su0q_u32(m[5][3], m[5][0]);
    m[6][3] = vsha256su0q_u32(m[6][3], m[6][0]);
    m[7][3] = vsha256su0q_u32(m[7][3], m[7][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][0] = vaddq_u32(m[0][0], vld1q_u32(&RC[0x30]));
    tmp[1][0] = vaddq_u32(m[1][0], vld1q_u32(&RC[0x30]));
    tmp[2][0] = vaddq_u32(m[2][0], vld1q_u32(&RC[0x30]));
    tmp[3][0] = vaddq_u32(m[3][0], vld1q_u32(&RC[0x30]));
    tmp[4][0] = vaddq_u32(m[4][0], vld1q_u32(&RC[0x30]));
    tmp[5][0] = vaddq_u32(m[5][0], vld1q_u32(&RC[0x30]));
    tmp[6][0] = vaddq_u32(m[6][0], vld1q_u32(&RC[0x30]));
    tmp[7][0] = vaddq_u32(m[7][0], vld1q_u32(&RC[0x30]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    m[0][3] = vsha256su1q_u32(m[0][3], m[0][1], m[0][2]);
    m[1][3] = vsha256su1q_u32(m[1][3], m[1][1], m[1][2]);
    m[2][3] = vsha256su1q_u32(m[2][3], m[2][1], m[2][2]);
    m[3][3] = vsha256su1q_u32(m[3][3], m[3][1], m[3][2]);
    m[4][3] = vsha256su1q_u32(m[4][3], m[4][1], m[4][2]);
    m[5][3] = vsha256su1q_u32(m[5][3], m[5][1], m[5][2]);
    m[6][3] = vsha256su1q_u32(m[6][3], m[6][1], m[6][2]);
    m[7][3] = vsha256su1q_u32(m[7][3], m[7][1], m[7][2]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][1], vld1q_u32(&RC[0x34]));
    tmp[1][1] = vaddq_u32(m[1][1], vld1q_u32(&RC[0x34]));
    tmp[2][1] = vaddq_u32(m[2][1], vld1q_u32(&RC[0x34]));
    tmp[3][1] = vaddq_u32(m[3][1], vld1q_u32(&RC[0x34]));
    tmp[4][1] = vaddq_u32(m[4][1], vld1q_u32(&RC[0x34]));
    tmp[5][1] = vaddq_u32(m[5][1], vld1q_u32(&RC[0x34]));
    tmp[6][1] = vaddq_u32(m[6][1], vld1q_u32(&RC[0x34]));
    tmp[7][1] = vaddq_u32(m[7][1], vld1q_u32(&RC[0x34]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][0] = vaddq_u32(m[0][2], vld1q_u32(&RC[0x38]));
    tmp[1][0] = vaddq_u32(m[1][2], vld1q_u32(&RC[0x38]));
    tmp[2][0] = vaddq_u32(m[2][2], vld1q_u32(&RC[0x38]));
    tmp[3][0] = vaddq_u32(m[3][2], vld1q_u32(&RC[0x38]));
    tmp[4][0] = vaddq_u32(m[4][2], vld1q_u32(&RC[0x38]));
    tmp[5][0] = vaddq_u32(m[5][2], vld1q_u32(&RC[0x38]));
    tmp[6][0] = vaddq_u32(m[6][2], vld1q_u32(&RC[0x38]));
    tmp[7][0] = vaddq_u32(m[7][2], vld1q_u32(&RC[0x38]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    tmp[0][1] = vaddq_u32(m[0][3], vld1q_u32(&RC[0x3c]));
    tmp[1][1] = vaddq_u32(m[1][3], vld1q_u32(&RC[0x3c]));
    tmp[2][1] = vaddq_u32(m[2][3], vld1q_u32(&RC[0x3c]));
    tmp[3][1] = vaddq_u32(m[3][3], vld1q_u32(&RC[0x3c]));
    tmp[4][1] = vaddq_u32(m[4][3], vld1q_u32(&RC[0x3c]));
    tmp[5][1] = vaddq_u32(m[5][3], vld1q_u32(&RC[0x3c]));
    tmp[6][1] = vaddq_u32(m[6][3], vld1q_u32(&RC[0x3c]));
    tmp[7][1] = vaddq_u32(m[7][3], vld1q_u32(&RC[0x3c]));
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][0]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][0]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][0]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][0]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][0]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][0]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][0]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][0]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][0]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][0]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][0]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][0]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][0]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][0]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][0]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][0]);
    tmp[0][2] = s[0][0];
    tmp[1][2] = s[1][0];
    tmp[2][2] = s[2][0];
    tmp[3][2] = s[3][0];
    tmp[4][2] = s[4][0];
    tmp[5][2] = s[5][0];
    tmp[6][2] = s[6][0];
    tmp[7][2] = s[7][0];
    s[0][0] = vsha256hq_u32(s[0][0], s[0][1], tmp[0][1]);
    s[1][0] = vsha256hq_u32(s[1][0], s[1][1], tmp[1][1]);
    s[2][0] = vsha256hq_u32(s[2][0], s[2][1], tmp[2][1]);
    s[3][0] = vsha256hq_u32(s[3][0], s[3][1], tmp[3][1]);
    s[4][0] = vsha256hq_u32(s[4][0], s[4][1], tmp[4][1]);
    s[5][0] = vsha256hq_u32(s[5][0], s[5][1], tmp[5][1]);
    s[6][0] = vsha256hq_u32(s[6][0], s[6][1], tmp[6][1]);
    s[7][0] = vsha256hq_u32(s[7][0], s[7][1], tmp[7][1]);
    s[0][1] = vsha256h2q_u32(s[0][1], tmp[0][2], tmp[0][1]);
    s[1][1] = vsha256h2q_u32(s[1][1], tmp[1][2], tmp[1][1]);
    s[2][1] = vsha256h2q_u32(s[2][1], tmp[2][2], tmp[2][1]);
    s[3][1] = vsha256h2q_u32(s[3][1], tmp[3][2], tmp[3][1]);
    s[4][1] = vsha256h2q_u32(s[4][1], tmp[4][2], tmp[4][1]);
    s[5][1] = vsha256h2q_u32(s[5][1], tmp[5][2], tmp[5][1]);
    s[6][1] = vsha256h2q_u32(s[6][1], tmp[6][2], tmp[6][1]);
    s[7][1] = vsha256h2q_u32(s[7][1], tmp[7][2], tmp[7][1]);
    s[0][0]  = vaddq_u32(s[0][0], s_save[0][0]);
    s[0][1]  = vaddq_u32(s[0][1], s_save[0][1]);
    s[1][0]  = vaddq_u32(s[1][0], s_save[1][0]);
    s[1][1]  = vaddq_u32(s[1][1], s_save[1][1]);
    s[2][0]  = vaddq_u32(s[2][0], s_save[2][0]);
    s[2][1]  = vaddq_u32(s[2][1], s_save[2][1]);
    s[3][0]  = vaddq_u32(s[3][0], s_save[3][0]);
    s[3][1]  = vaddq_u32(s[3][1], s_save[3][1]);
    s[4][0]  = vaddq_u32(s[4][0], s_save[4][0]);
    s[4][1]  = vaddq_u32(s[4][1], s_save[4][1]);
    s[5][0]  = vaddq_u32(s[5][0], s_save[5][0]);
    s[5][1]  = vaddq_u32(s[5][1], s_save[5][1]);
    s[6][0]  = vaddq_u32(s[6][0], s_save[6][0]);
    s[6][1]  = vaddq_u32(s[6][1], s_save[6][1]);
    s[7][0]  = vaddq_u32(s[7][0], s_save[7][0]);
    s[7][1]  = vaddq_u32(s[7][1], s_save[7][1]);
    vst1q_u32((uint32_t*)(out + 0), s[0][0]);
    vst1q_u32((uint32_t*)(out + 16), s[0][1]);
    vst1q_u32((uint32_t*)(out + 32), s[1][0]);
    vst1q_u32((uint32_t*)(out + 48), s[1][1]);
    vst1q_u32((uint32_t*)(out + 64), s[2][0]);
    vst1q_u32((uint32_t*)(out + 80), s[2][1]);
    vst1q_u32((uint32_t*)(out + 96), s[3][0]);
    vst1q_u32((uint32_t*)(out + 112), s[3][1]);
    vst1q_u32((uint32_t*)(out + 128), s[4][0]);
    vst1q_u32((uint32_t*)(out + 144), s[4][1]);
    vst1q_u32((uint32_t*)(out + 160), s[5][0]);
    vst1q_u32((uint32_t*)(out + 176), s[5][1]);
    vst1q_u32((uint32_t*)(out + 192), s[6][0]);
    vst1q_u32((uint32_t*)(out + 208), s[6][1]);
    vst1q_u32((uint32_t*)(out + 224), s[7][0]);
    vst1q_u32((uint32_t*)(out + 240), s[7][1]);
}
